{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h1 align=\"center\">Python Bootcamp</h1> \n",
        "<h3 align=\"center\">BSAI course, Autumn, 2025</h3>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
        "<center><h1>Introduction to Scikit-Learn: Machine Learning in Python</h1></center>\n",
        "\n",
        "<p>Welcome to the world of machine learning with scikit-learn! This notebook will introduce you to the most popular machine learning library in Python, covering essential algorithms and best practices.\n",
        "\n",
        "<p><strong>Learning Objectives:</strong>\n",
        "<ul>\n",
        "<li>Understand the scikit-learn API and design principles</li>\n",
        "<li>Learn to implement linear regression for prediction</li>\n",
        "<li>Master Principal Component Analysis (PCA) for dimensionality reduction</li>\n",
        "<li>Explore classification algorithms (Logistic Regression, Decision Trees)</li>\n",
        "<li>Understand model evaluation and validation techniques</li>\n",
        "<li>Practice data preprocessing and feature engineering</li>\n",
        "</ul>\n",
        "\n",
        "<p><strong>Key Concepts:</strong>\n",
        "<ul>\n",
        "<li><strong>Estimator API:</strong> Consistent interface for all algorithms</li>\n",
        "<li><strong>Supervised Learning:</strong> Learning from labeled data</li>\n",
        "<li><strong>Unsupervised Learning:</strong> Finding patterns in unlabeled data</li>\n",
        "<li><strong>Model Evaluation:</strong> Measuring algorithm performance</li>\n",
        "<li><strong>Cross-validation:</strong> Robust model assessment</li>\n",
        "</ul>\n",
        "\n",
        "<p><strong>What You'll Learn:</strong>\n",
        "<ul>\n",
        "<li><strong>Linear Regression:</strong> Predicting continuous values</li>\n",
        "<li><strong>PCA:</strong> Reducing dimensionality while preserving information</li>\n",
        "<li><strong>Classification:</strong> Categorizing data into classes</li>\n",
        "<li><strong>Model Selection:</strong> Choosing the best algorithm and parameters</li>\n",
        "<li><strong>Data Preprocessing:</strong> Preparing data for machine learning</li>\n",
        "</ul>\n",
        "\n",
        "<p><strong>Resources:</strong>\n",
        "<ul>\n",
        "<li><a href=\"https://scikit-learn.org/stable/\">Scikit-Learn Official Documentation</a></li>\n",
        "<li><a href=\"https://scikit-learn.org/stable/user_guide.html\">User Guide</a></li>\n",
        "<li><a href=\"https://scikit-learn.org/stable/modules/classes.html\">API Reference</a></li>\n",
        "<li><a href=\"https://scikit-learn.org/stable/auto_examples/index.html\">Examples Gallery</a></li>\n",
        "</ul>\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
        "<h2>1. Introduction to Scikit-Learn</h2>\n",
        "\n",
        "<p>Scikit-learn is a powerful and user-friendly machine learning library for Python. It provides a wide range of supervised and unsupervised learning algorithms through a consistent interface.\n",
        "\n",
        "<p><strong>Key Features:</strong>\n",
        "<ul>\n",
        "<li><strong>Consistent API:</strong> All algorithms follow the same fit/predict/transform pattern</li>\n",
        "<li><strong>Comprehensive:</strong> Covers classification, regression, clustering, dimensionality reduction</li>\n",
        "<li><strong>Well-documented:</strong> Extensive documentation and examples</li>\n",
        "<li><strong>Production-ready:</strong> Used in industry and research</li>\n",
        "<li><strong>Open source:</strong> Free to use and modify</li>\n",
        "</ul>\n",
        "\n",
        "<p><strong>Scikit-Learn Design Principles:</strong>\n",
        "<ul>\n",
        "<li><strong>Consistency:</strong> All objects share a common interface</li>\n",
        "<li><strong>Inspection:</strong> All parameters are accessible as public attributes</li>\n",
        "<li><strong>Non-proliferation:</strong> Limited number of classes and methods</li>\n",
        "<li><strong>Composition:</strong> Complex algorithms built from simpler building blocks</li>\n",
        "<li><strong>Sensible defaults:</strong> Good default parameters for most use cases</li>\n",
        "</ul>\n",
        "\n",
        "<p><strong>Common Workflow:</strong>\n",
        "<ol>\n",
        "<li><strong>Data Preparation:</strong> Load and preprocess your data</li>\n",
        "<li><strong>Model Selection:</strong> Choose appropriate algorithm</li>\n",
        "<li><strong>Training:</strong> Fit the model to your data</li>\n",
        "<li><strong>Prediction:</strong> Make predictions on new data</li>\n",
        "<li><strong>Evaluation:</strong> Assess model performance</li>\n",
        "</ol>\n",
        "\n",
        "<p>Let's start by importing the necessary libraries and exploring the basic structure:\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import essential libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# Configure matplotlib for better plots\n",
        "plt.style.use('default')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "print(\"Libraries imported successfully!\")\n",
        "print(f\"NumPy version: {np.__version__}\")\n",
        "print(f\"Pandas version: {pd.__version__}\")\n",
        "\n",
        "# Check scikit-learn version\n",
        "try:\n",
        "    import sklearn\n",
        "    print(f\"Scikit-learn version: {sklearn.__version__}\")\n",
        "except ImportError:\n",
        "    print(\"Scikit-learn not installed. Please install with: pip install scikit-learn\")\n",
        "\n",
        "# Display available datasets\n",
        "print(\"\\n=== Available Built-in Datasets ===\")\n",
        "print(\"Some popular datasets in scikit-learn:\")\n",
        "print(\"- load_iris(): Iris flower dataset (classification)\")\n",
        "print(\"- load_wine(): Wine recognition dataset (classification)\")\n",
        "print(\"- load_breast_cancer(): Breast cancer dataset (classification)\")\n",
        "print(\"- load_digits(): Handwritten digits dataset (classification)\")\n",
        "print(\"- load_boston(): Boston housing dataset (regression)\")\n",
        "print(\"- load_diabetes(): Diabetes dataset (regression)\")\n",
        "print(\"- make_classification(): Generate synthetic classification data\")\n",
        "print(\"- make_regression(): Generate synthetic regression data\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
        "<h2>2. Linear Regression: Predicting Continuous Values</h2>\n",
        "\n",
        "<p>Linear regression is one of the most fundamental algorithms in machine learning. It's used to predict continuous numerical values based on input features.\n",
        "\n",
        "<p><strong>Key Concepts:</strong>\n",
        "<ul>\n",
        "<li><strong>Supervised Learning:</strong> Learning from labeled training data</li>\n",
        "<li><strong>Regression:</strong> Predicting continuous numerical values</li>\n",
        "<li><strong>Linear Relationship:</strong> Assuming a linear relationship between features and target</li>\n",
        "<li><strong>Least Squares:</strong> Minimizing the sum of squared errors</li>\n",
        "</ul>\n",
        "\n",
        "<p><strong>Mathematical Foundation:</strong>\n",
        "<p>Linear regression finds the best line (or hyperplane) that fits the data by minimizing the sum of squared residuals:\n",
        "<p><strong>y = β₀ + β₁x₁ + β₂x₂ + ... + βₙxₙ + ε</strong>\n",
        "\n",
        "<p>Where:\n",
        "<ul>\n",
        "<li><strong>y:</strong> Target variable (what we want to predict)</li>\n",
        "<li><strong>x₁, x₂, ..., xₙ:</strong> Feature variables (input data)</li>\n",
        "<li><strong>β₀:</strong> Intercept (bias term)</li>\n",
        "<li><strong>β₁, β₂, ..., βₙ:</strong> Coefficients (weights)</li>\n",
        "<li><strong>ε:</strong> Error term (residuals)</li>\n",
        "</ul>\n",
        "\n",
        "<p><strong>Scikit-Learn Implementation:</strong>\n",
        "<ul>\n",
        "<li><strong>LinearRegression:</strong> Basic linear regression</li>\n",
        "<li><strong>Ridge:</strong> Linear regression with L2 regularization</li>\n",
        "<li><strong>Lasso:</strong> Linear regression with L1 regularization</li>\n",
        "<li><strong>ElasticNet:</strong> Combination of L1 and L2 regularization</li>\n",
        "</ul>\n",
        "\n",
        "<p>Let's start with a practical example using the Boston housing dataset:\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the Boston housing dataset\n",
        "from sklearn.datasets import load_boston\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Load the dataset\n",
        "boston = load_boston()\n",
        "X = boston.data  # Features\n",
        "y = boston.target  # Target variable (house prices)\n",
        "\n",
        "print(\"=== Boston Housing Dataset ===\")\n",
        "print(f\"Dataset shape: {X.shape}\")\n",
        "print(f\"Number of features: {X.shape[1]}\")\n",
        "print(f\"Number of samples: {X.shape[0]}\")\n",
        "print(f\"Feature names: {boston.feature_names}\")\n",
        "print(f\"Target variable: {boston.target_names[0] if hasattr(boston, 'target_names') else 'House prices'}\")\n",
        "\n",
        "# Create a DataFrame for easier exploration\n",
        "df = pd.DataFrame(X, columns=boston.feature_names)\n",
        "df['PRICE'] = y\n",
        "\n",
        "print(\"\\n=== Dataset Overview ===\")\n",
        "print(df.head())\n",
        "\n",
        "print(\"\\n=== Dataset Statistics ===\")\n",
        "print(df.describe())\n",
        "\n",
        "# Check for missing values\n",
        "print(f\"\\nMissing values: {df.isnull().sum().sum()}\")\n",
        "\n",
        "# Visualize the relationship between features and target\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "axes = axes.ravel()\n",
        "\n",
        "# Plot some key features against price\n",
        "features_to_plot = ['RM', 'LSTAT', 'PTRATIO', 'INDUS']\n",
        "for i, feature in enumerate(features_to_plot):\n",
        "    axes[i].scatter(df[feature], df['PRICE'], alpha=0.6)\n",
        "    axes[i].set_xlabel(feature)\n",
        "    axes[i].set_ylabel('Price')\n",
        "    axes[i].set_title(f'{feature} vs Price')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Correlation analysis\n",
        "plt.figure(figsize=(12, 8))\n",
        "correlation_matrix = df.corr()\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0)\n",
        "plt.title('Feature Correlation Matrix')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"=== Data Split ===\")\n",
        "print(f\"Training set size: {X_train.shape[0]} samples\")\n",
        "print(f\"Test set size: {X_test.shape[0]} samples\")\n",
        "print(f\"Number of features: {X_train.shape[1]}\")\n",
        "\n",
        "# Standardize the features (important for some algorithms)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "print(\"\\n=== Feature Standardization ===\")\n",
        "print(\"Features have been standardized (mean=0, std=1)\")\n",
        "print(f\"Training set mean: {X_train_scaled.mean(axis=0)[:5]}\")  # First 5 features\n",
        "print(f\"Training set std: {X_train_scaled.std(axis=0)[:5]}\")    # First 5 features\n",
        "\n",
        "# Train different linear regression models\n",
        "models = {\n",
        "    'Linear Regression': LinearRegression(),\n",
        "    'Ridge Regression': Ridge(alpha=1.0),\n",
        "    'Lasso Regression': Lasso(alpha=1.0)\n",
        "}\n",
        "\n",
        "results = {}\n",
        "\n",
        "print(\"\\n=== Training Models ===\")\n",
        "for name, model in models.items():\n",
        "    # Train the model\n",
        "    model.fit(X_train_scaled, y_train)\n",
        "    \n",
        "    # Make predictions\n",
        "    y_train_pred = model.predict(X_train_scaled)\n",
        "    y_test_pred = model.predict(X_test_scaled)\n",
        "    \n",
        "    # Calculate metrics\n",
        "    train_mse = mean_squared_error(y_train, y_train_pred)\n",
        "    test_mse = mean_squared_error(y_test, y_test_pred)\n",
        "    train_r2 = r2_score(y_train, y_train_pred)\n",
        "    test_r2 = r2_score(y_test, y_test_pred)\n",
        "    \n",
        "    results[name] = {\n",
        "        'model': model,\n",
        "        'train_mse': train_mse,\n",
        "        'test_mse': test_mse,\n",
        "        'train_r2': train_r2,\n",
        "        'test_r2': test_r2,\n",
        "        'predictions': y_test_pred\n",
        "    }\n",
        "    \n",
        "    print(f\"{name}:\")\n",
        "    print(f\"  Training MSE: {train_mse:.2f}, R²: {train_r2:.3f}\")\n",
        "    print(f\"  Test MSE: {test_mse:.2f}, R²: {test_r2:.3f}\")\n",
        "    print()\n",
        "\n",
        "# Compare model performance\n",
        "print(\"=== Model Comparison ===\")\n",
        "comparison_df = pd.DataFrame({\n",
        "    'Model': list(results.keys()),\n",
        "    'Train R²': [results[name]['train_r2'] for name in results.keys()],\n",
        "    'Test R²': [results[name]['test_r2'] for name in results.keys()],\n",
        "    'Train MSE': [results[name]['train_mse'] for name in results.keys()],\n",
        "    'Test MSE': [results[name]['test_mse'] for name in results.keys()]\n",
        "})\n",
        "\n",
        "print(comparison_df.round(3))\n",
        "\n",
        "# Visualize predictions vs actual values\n",
        "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
        "\n",
        "for i, (name, result) in enumerate(results.items()):\n",
        "    axes[i].scatter(y_test, result['predictions'], alpha=0.6)\n",
        "    axes[i].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
        "    axes[i].set_xlabel('Actual Price')\n",
        "    axes[i].set_ylabel('Predicted Price')\n",
        "    axes[i].set_title(f'{name}\\nR² = {result[\"test_r2\"]:.3f}')\n",
        "    axes[i].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Feature importance (coefficients)\n",
        "print(\"\\n=== Feature Importance (Linear Regression) ===\")\n",
        "lr_model = results['Linear Regression']['model']\n",
        "feature_importance = pd.DataFrame({\n",
        "    'Feature': boston.feature_names,\n",
        "    'Coefficient': lr_model.coef_\n",
        "}).sort_values('Coefficient', key=abs, ascending=False)\n",
        "\n",
        "print(feature_importance)\n",
        "\n",
        "# Plot feature importance\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.barh(feature_importance['Feature'], feature_importance['Coefficient'])\n",
        "plt.xlabel('Coefficient Value')\n",
        "plt.title('Feature Importance (Linear Regression Coefficients)')\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
        "<h2>3. Principal Component Analysis (PCA): Dimensionality Reduction</h2>\n",
        "\n",
        "<p>PCA is a powerful unsupervised learning technique used to reduce the dimensionality of data while preserving as much information as possible. It's particularly useful for visualization and noise reduction.\n",
        "\n",
        "<p><strong>Key Concepts:</strong>\n",
        "<ul>\n",
        "<li><strong>Unsupervised Learning:</strong> No target variable needed</li>\n",
        "<li><strong>Dimensionality Reduction:</strong> Reducing the number of features</li>\n",
        "<li><strong>Variance Preservation:</strong> Keeping the most important information</li>\n",
        "<li><strong>Orthogonal Components:</strong> New features are uncorrelated</li>\n",
        "</ul>\n",
        "\n",
        "<p><strong>Mathematical Foundation:</strong>\n",
        "<p>PCA finds the directions (principal components) of maximum variance in the data:\n",
        "<ol>\n",
        "<li><strong>Standardize the data</strong> (mean=0, std=1)</li>\n",
        "<li><strong>Calculate covariance matrix</strong> of the features</li>\n",
        "<li><strong>Find eigenvalues and eigenvectors</strong> of the covariance matrix</li>\n",
        "<li><strong>Sort by eigenvalues</strong> (largest first)</li>\n",
        "<li><strong>Transform data</strong> to new coordinate system</li>\n",
        "</ol>\n",
        "\n",
        "<p><strong>Applications:</strong>\n",
        "<ul>\n",
        "<li><strong>Data Visualization:</strong> Reduce to 2D/3D for plotting</li>\n",
        "<li><strong>Noise Reduction:</strong> Remove less important components</li>\n",
        "<li><strong>Feature Engineering:</strong> Create new uncorrelated features</li>\n",
        "<li><strong>Preprocessing:</strong> Reduce dimensionality before other algorithms</li>\n",
        "</ul>\n",
        "\n",
        "<p><strong>Scikit-Learn Implementation:</strong>\n",
        "<ul>\n",
        "<li><strong>PCA:</strong> Basic principal component analysis</li>\n",
        "<li><strong>IncrementalPCA:</strong> For large datasets</li>\n",
        "<li><strong>KernelPCA:</strong> Non-linear dimensionality reduction</li>\n",
        "<li><strong>SparsePCA:</strong> Sparse principal components</li>\n",
        "</ul>\n",
        "\n",
        "<p>Let's explore PCA using the Iris dataset:\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the Iris dataset\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load the dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "feature_names = iris.feature_names\n",
        "target_names = iris.target_names\n",
        "\n",
        "print(\"=== Iris Dataset ===\")\n",
        "print(f\"Dataset shape: {X.shape}\")\n",
        "print(f\"Number of features: {X.shape[1]}\")\n",
        "print(f\"Number of samples: {X.shape[0]}\")\n",
        "print(f\"Feature names: {feature_names}\")\n",
        "print(f\"Target classes: {target_names}\")\n",
        "\n",
        "# Create a DataFrame for easier exploration\n",
        "df_iris = pd.DataFrame(X, columns=feature_names)\n",
        "df_iris['species'] = [target_names[i] for i in y]\n",
        "\n",
        "print(\"\\n=== Dataset Overview ===\")\n",
        "print(df_iris.head())\n",
        "\n",
        "print(\"\\n=== Dataset Statistics ===\")\n",
        "print(df_iris.describe())\n",
        "\n",
        "# Visualize the original data\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "axes = axes.ravel()\n",
        "\n",
        "# Plot pairwise relationships\n",
        "for i, feature in enumerate(feature_names):\n",
        "    axes[i].scatter(df_iris[feature], df_iris['species'], alpha=0.7)\n",
        "    axes[i].set_xlabel(feature)\n",
        "    axes[i].set_ylabel('Species')\n",
        "    axes[i].set_title(f'{feature} vs Species')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "print(\"\\n=== Feature Standardization ===\")\n",
        "print(\"Features have been standardized (mean=0, std=1)\")\n",
        "print(f\"Mean: {X_scaled.mean(axis=0)}\")\n",
        "print(f\"Std: {X_scaled.std(axis=0)}\")\n",
        "\n",
        "# Apply PCA\n",
        "pca = PCA()\n",
        "X_pca = pca.fit_transform(X_scaled)\n",
        "\n",
        "print(\"\\n=== PCA Results ===\")\n",
        "print(f\"Explained variance ratio: {pca.explained_variance_ratio_}\")\n",
        "print(f\"Cumulative explained variance: {np.cumsum(pca.explained_variance_ratio_)}\")\n",
        "\n",
        "# Visualize explained variance\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.bar(range(1, len(pca.explained_variance_ratio_) + 1), pca.explained_variance_ratio_)\n",
        "plt.xlabel('Principal Component')\n",
        "plt.ylabel('Explained Variance Ratio')\n",
        "plt.title('Explained Variance by Component')\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(range(1, len(pca.explained_variance_ratio_) + 1), \n",
        "         np.cumsum(pca.explained_variance_ratio_), 'bo-')\n",
        "plt.xlabel('Number of Components')\n",
        "plt.ylabel('Cumulative Explained Variance')\n",
        "plt.title('Cumulative Explained Variance')\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Create PCA with 2 components for visualization\n",
        "pca_2d = PCA(n_components=2)\n",
        "X_pca_2d = pca_2d.fit_transform(X_scaled)\n",
        "\n",
        "print(f\"\\n=== 2D PCA ===\")\n",
        "print(f\"Explained variance ratio (2 components): {pca_2d.explained_variance_ratio_}\")\n",
        "print(f\"Total variance explained: {pca_2d.explained_variance_ratio_.sum():.3f}\")\n",
        "\n",
        "# Visualize 2D PCA\n",
        "plt.figure(figsize=(10, 8))\n",
        "colors = ['red', 'green', 'blue']\n",
        "for i, (color, target_name) in enumerate(zip(colors, target_names)):\n",
        "    plt.scatter(X_pca_2d[y == i, 0], X_pca_2d[y == i, 1], \n",
        "                c=color, label=target_name, alpha=0.7, s=50)\n",
        "\n",
        "plt.xlabel(f'First Principal Component ({pca_2d.explained_variance_ratio_[0]:.2%} variance)')\n",
        "plt.ylabel(f'Second Principal Component ({pca_2d.explained_variance_ratio_[1]:.2%} variance)')\n",
        "plt.title('PCA: Iris Dataset (2D Projection)')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.show()\n",
        "\n",
        "# Compare original vs PCA features\n",
        "print(\"\\n=== Feature Comparison ===\")\n",
        "print(\"Original features vs Principal Components\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Show how original features contribute to principal components\n",
        "components_df = pd.DataFrame(\n",
        "    pca_2d.components_.T,\n",
        "    columns=['PC1', 'PC2'],\n",
        "    index=feature_names\n",
        ")\n",
        "print(components_df.round(3))\n",
        "\n",
        "# Visualize feature contributions\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.barh(feature_names, pca_2d.components_[0], alpha=0.7, label='PC1')\n",
        "plt.barh(feature_names, pca_2d.components_[1], alpha=0.7, label='PC2')\n",
        "plt.xlabel('Component Value')\n",
        "plt.title('Feature Contributions to Principal Components')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
        "<h2>4. Classification: Categorizing Data</h2>\n",
        "\n",
        "<p>Classification is a supervised learning task where we predict categorical labels. Scikit-learn provides many classification algorithms, each with its own strengths and use cases.\n",
        "\n",
        "<p><strong>Key Concepts:</strong>\n",
        "<ul>\n",
        "<li><strong>Supervised Learning:</strong> Learning from labeled training data</li>\n",
        "<li><strong>Classification:</strong> Predicting categorical labels</li>\n",
        "<li><strong>Binary Classification:</strong> Two classes (e.g., spam/not spam)</li>\n",
        "<li><strong>Multi-class Classification:</strong> Multiple classes (e.g., species)</li>\n",
        "</ul>\n",
        "\n",
        "<p><strong>Common Classification Algorithms:</strong>\n",
        "<ul>\n",
        "<li><strong>Logistic Regression:</strong> Linear decision boundary, probabilistic output</li>\n",
        "<li><strong>Decision Trees:</strong> Non-linear, interpretable, can handle mixed data types</li>\n",
        "<li><strong>Random Forest:</strong> Ensemble of decision trees, robust and accurate</li>\n",
        "<li><strong>Support Vector Machines (SVM):</strong> Powerful for high-dimensional data</li>\n",
        "<li><strong>K-Nearest Neighbors (KNN):</strong> Simple, instance-based learning</li>\n",
        "</ul>\n",
        "\n",
        "<p><strong>Evaluation Metrics:</strong>\n",
        "<ul>\n",
        "<li><strong>Accuracy:</strong> Percentage of correct predictions</li>\n",
        "<li><strong>Precision:</strong> True positives / (True positives + False positives)</li>\n",
        "<li><strong>Recall:</strong> True positives / (True positives + False negatives)</li>\n",
        "<li><strong>F1-Score:</strong> Harmonic mean of precision and recall</li>\n",
        "<li><strong>Confusion Matrix:</strong> Detailed breakdown of predictions</li>\n",
        "</ul>\n",
        "\n",
        "<p>Let's explore classification using the Wine dataset:\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the Wine dataset\n",
        "from sklearn.datasets import load_wine\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# Load the dataset\n",
        "wine = load_wine()\n",
        "X = wine.data\n",
        "y = wine.target\n",
        "feature_names = wine.feature_names\n",
        "target_names = wine.target_names\n",
        "\n",
        "print(\"=== Wine Dataset ===\")\n",
        "print(f\"Dataset shape: {X.shape}\")\n",
        "print(f\"Number of features: {X.shape[1]}\")\n",
        "print(f\"Number of samples: {X.shape[0]}\")\n",
        "print(f\"Number of classes: {len(target_names)}\")\n",
        "print(f\"Class names: {target_names}\")\n",
        "\n",
        "# Create a DataFrame for easier exploration\n",
        "df_wine = pd.DataFrame(X, columns=feature_names)\n",
        "df_wine['wine_type'] = [target_names[i] for i in y]\n",
        "\n",
        "print(\"\\n=== Dataset Overview ===\")\n",
        "print(df_wine.head())\n",
        "\n",
        "print(\"\\n=== Class Distribution ===\")\n",
        "class_counts = pd.Series(y).value_counts().sort_index()\n",
        "for i, count in enumerate(class_counts):\n",
        "    print(f\"{target_names[i]}: {count} samples\")\n",
        "\n",
        "# Visualize the data\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "axes = axes.ravel()\n",
        "\n",
        "# Plot some key features\n",
        "features_to_plot = ['alcohol', 'malic_acid', 'ash', 'alcalinity_of_ash']\n",
        "for i, feature in enumerate(features_to_plot):\n",
        "    for j, target_name in enumerate(target_names):\n",
        "        mask = y == j\n",
        "        axes[i].scatter(df_wine.loc[mask, feature], \n",
        "                       [j] * mask.sum(), \n",
        "                       label=target_name, alpha=0.7, s=50)\n",
        "    axes[i].set_xlabel(feature)\n",
        "    axes[i].set_ylabel('Wine Type')\n",
        "    axes[i].set_title(f'{feature} vs Wine Type')\n",
        "    axes[i].legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "print(\"\\n=== Data Split ===\")\n",
        "print(f\"Training set size: {X_train.shape[0]} samples\")\n",
        "print(f\"Test set size: {X_test.shape[0]} samples\")\n",
        "\n",
        "# Train different classification models\n",
        "classifiers = {\n",
        "    'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000),\n",
        "    'Decision Tree': DecisionTreeClassifier(random_state=42),\n",
        "    'Random Forest': RandomForestClassifier(random_state=42, n_estimators=100),\n",
        "    'SVM': SVC(random_state=42),\n",
        "    'K-Nearest Neighbors': KNeighborsClassifier(n_neighbors=3)\n",
        "}\n",
        "\n",
        "results = {}\n",
        "\n",
        "print(\"\\n=== Training Classification Models ===\")\n",
        "for name, classifier in classifiers.items():\n",
        "    # Train the model\n",
        "    classifier.fit(X_train_scaled, y_train)\n",
        "    \n",
        "    # Make predictions\n",
        "    y_train_pred = classifier.predict(X_train_scaled)\n",
        "    y_test_pred = classifier.predict(X_test_scaled)\n",
        "    \n",
        "    # Calculate accuracy\n",
        "    train_accuracy = accuracy_score(y_train, y_train_pred)\n",
        "    test_accuracy = accuracy_score(y_test, y_test_pred)\n",
        "    \n",
        "    # Cross-validation\n",
        "    cv_scores = cross_val_score(classifier, X_train_scaled, y_train, cv=5)\n",
        "    \n",
        "    results[name] = {\n",
        "        'classifier': classifier,\n",
        "        'train_accuracy': train_accuracy,\n",
        "        'test_accuracy': test_accuracy,\n",
        "        'cv_mean': cv_scores.mean(),\n",
        "        'cv_std': cv_scores.std(),\n",
        "        'predictions': y_test_pred\n",
        "    }\n",
        "    \n",
        "    print(f\"{name}:\")\n",
        "    print(f\"  Training Accuracy: {train_accuracy:.3f}\")\n",
        "    print(f\"  Test Accuracy: {test_accuracy:.3f}\")\n",
        "    print(f\"  CV Accuracy: {cv_scores.mean():.3f} (+/- {cv_scores.std() * 2:.3f})\")\n",
        "    print()\n",
        "\n",
        "# Compare model performance\n",
        "print(\"=== Model Comparison ===\")\n",
        "comparison_df = pd.DataFrame({\n",
        "    'Model': list(results.keys()),\n",
        "    'Train Accuracy': [results[name]['train_accuracy'] for name in results.keys()],\n",
        "    'Test Accuracy': [results[name]['test_accuracy'] for name in results.keys()],\n",
        "    'CV Mean': [results[name]['cv_mean'] for name in results.keys()],\n",
        "    'CV Std': [results[name]['cv_std'] for name in results.keys()]\n",
        "})\n",
        "\n",
        "print(comparison_df.round(3))\n",
        "\n",
        "# Visualize model performance\n",
        "plt.figure(figsize=(12, 6))\n",
        "x_pos = np.arange(len(results))\n",
        "width = 0.25\n",
        "\n",
        "plt.bar(x_pos - width, [results[name]['train_accuracy'] for name in results.keys()], \n",
        "        width, label='Train Accuracy', alpha=0.8)\n",
        "plt.bar(x_pos, [results[name]['test_accuracy'] for name in results.keys()], \n",
        "        width, label='Test Accuracy', alpha=0.8)\n",
        "plt.bar(x_pos + width, [results[name]['cv_mean'] for name in results.keys()], \n",
        "        width, label='CV Mean', alpha=0.8)\n",
        "\n",
        "plt.xlabel('Model')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Model Performance Comparison')\n",
        "plt.xticks(x_pos, list(results.keys()), rotation=45)\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Detailed evaluation of the best model\n",
        "best_model_name = max(results.keys(), key=lambda x: results[x]['test_accuracy'])\n",
        "best_model = results[best_model_name]['classifier']\n",
        "best_predictions = results[best_model_name]['predictions']\n",
        "\n",
        "print(f\"\\n=== Detailed Evaluation: {best_model_name} ===\")\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, best_predictions, target_names=target_names))\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_test, best_predictions)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
        "            xticklabels=target_names, yticklabels=target_names)\n",
        "plt.title(f'Confusion Matrix: {best_model_name}')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.show()\n",
        "\n",
        "# Feature importance (for tree-based models)\n",
        "if hasattr(best_model, 'feature_importances_'):\n",
        "    print(f\"\\n=== Feature Importance: {best_model_name} ===\")\n",
        "    feature_importance = pd.DataFrame({\n",
        "        'Feature': feature_names,\n",
        "        'Importance': best_model.feature_importances_\n",
        "    }).sort_values('Importance', ascending=False)\n",
        "    \n",
        "    print(feature_importance.head(10))\n",
        "    \n",
        "    # Plot feature importance\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    top_features = feature_importance.head(10)\n",
        "    plt.barh(top_features['Feature'], top_features['Importance'])\n",
        "    plt.xlabel('Importance')\n",
        "    plt.title(f'Top 10 Feature Importance: {best_model_name}')\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
        "<h2>5. Model Evaluation and Validation</h2>\n",
        "\n",
        "<p>Proper model evaluation is crucial for understanding how well your machine learning model will perform on new, unseen data. Scikit-learn provides comprehensive tools for model evaluation and validation.\n",
        "\n",
        "<p><strong>Key Concepts:</strong>\n",
        "<ul>\n",
        "<li><strong>Train-Test Split:</strong> Dividing data into training and testing sets</li>\n",
        "<li><strong>Cross-Validation:</strong> More robust evaluation using multiple train-test splits</li>\n",
        "<li><strong>Overfitting:</strong> Model performs well on training data but poorly on test data</li>\n",
        "<li><strong>Underfitting:</strong> Model is too simple to capture the underlying patterns</li>\n",
        "</ul>\n",
        "\n",
        "<p><strong>Evaluation Strategies:</strong>\n",
        "<ul>\n",
        "<li><strong>Hold-out Validation:</strong> Simple train-test split</li>\n",
        "<li><strong>K-Fold Cross-Validation:</strong> K different train-test splits</li>\n",
        "<li><strong>Stratified K-Fold:</strong> Maintains class distribution in each fold</li>\n",
        "<li><strong>Leave-One-Out:</strong> Each sample is used once as test set</li>\n",
        "</ul>\n",
        "\n",
        "<p><strong>Common Metrics:</strong>\n",
        "<ul>\n",
        "<li><strong>Regression:</strong> MSE, RMSE, MAE, R²</li>\n",
        "<li><strong>Classification:</strong> Accuracy, Precision, Recall, F1-Score</li>\n",
        "<li><strong>Model Selection:</strong> Cross-validation scores, learning curves</li>\n",
        "</ul>\n",
        "\n",
        "<p>Let's explore model evaluation techniques:\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Model evaluation and validation techniques\n",
        "from sklearn.model_selection import cross_val_score, validation_curve, learning_curve\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Generate synthetic data for demonstration\n",
        "from sklearn.datasets import make_regression, make_classification\n",
        "\n",
        "print(\"=== Model Evaluation Techniques ===\")\n",
        "\n",
        "# 1. Cross-Validation for Regression\n",
        "print(\"\\n1. Cross-Validation for Regression\")\n",
        "X_reg, y_reg = make_regression(n_samples=1000, n_features=10, noise=0.1, random_state=42)\n",
        "\n",
        "# Different cross-validation strategies\n",
        "cv_strategies = {\n",
        "    '5-Fold CV': 5,\n",
        "    '10-Fold CV': 10,\n",
        "    'Leave-One-Out': len(X_reg)  # Leave-One-Out\n",
        "}\n",
        "\n",
        "regression_models = {\n",
        "    'Linear Regression': LinearRegression(),\n",
        "    'Ridge': Ridge(alpha=1.0),\n",
        "    'Lasso': Lasso(alpha=1.0)\n",
        "}\n",
        "\n",
        "print(\"Cross-Validation Results (R² Score):\")\n",
        "for model_name, model in regression_models.items():\n",
        "    print(f\"\\n{model_name}:\")\n",
        "    for cv_name, cv_folds in cv_strategies.items():\n",
        "        if cv_folds == len(X_reg):\n",
        "            # Leave-One-Out is computationally expensive, so we'll skip it for demo\n",
        "            continue\n",
        "        scores = cross_val_score(model, X_reg, y_reg, cv=cv_folds, scoring='r2')\n",
        "        print(f\"  {cv_name}: {scores.mean():.3f} (+/- {scores.std() * 2:.3f})\")\n",
        "\n",
        "# 2. Cross-Validation for Classification\n",
        "print(\"\\n2. Cross-Validation for Classification\")\n",
        "X_clf, y_clf = make_classification(n_samples=1000, n_features=10, n_classes=3, \n",
        "                                  n_redundant=2, random_state=42)\n",
        "\n",
        "classification_models = {\n",
        "    'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000),\n",
        "    'Decision Tree': DecisionTreeClassifier(random_state=42),\n",
        "    'Random Forest': RandomForestClassifier(random_state=42, n_estimators=100)\n",
        "}\n",
        "\n",
        "print(\"Cross-Validation Results (Accuracy):\")\n",
        "for model_name, model in classification_models.items():\n",
        "    print(f\"\\n{model_name}:\")\n",
        "    for cv_name, cv_folds in cv_strategies.items():\n",
        "        if cv_folds == len(X_clf):\n",
        "            continue\n",
        "        scores = cross_val_score(model, X_clf, y_clf, cv=cv_folds, scoring='accuracy')\n",
        "        print(f\"  {cv_name}: {scores.mean():.3f} (+/- {scores.std() * 2:.3f})\")\n",
        "\n",
        "# 3. Validation Curves - Understanding model complexity\n",
        "print(\"\\n3. Validation Curves\")\n",
        "print(\"Analyzing how model performance changes with complexity...\")\n",
        "\n",
        "# Example: Decision Tree depth vs performance\n",
        "param_range = np.arange(1, 21)\n",
        "train_scores, val_scores = validation_curve(\n",
        "    DecisionTreeClassifier(random_state=42), X_clf, y_clf,\n",
        "    param_name='max_depth', param_range=param_range,\n",
        "    cv=5, scoring='accuracy', n_jobs=-1\n",
        ")\n",
        "\n",
        "# Calculate mean and std\n",
        "train_mean = np.mean(train_scores, axis=1)\n",
        "train_std = np.std(train_scores, axis=1)\n",
        "val_mean = np.mean(val_scores, axis=1)\n",
        "val_std = np.std(val_scores, axis=1)\n",
        "\n",
        "# Plot validation curve\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(param_range, train_mean, 'o-', color='blue', label='Training Score')\n",
        "plt.fill_between(param_range, train_mean - train_std, train_mean + train_std, \n",
        "                 alpha=0.1, color='blue')\n",
        "plt.plot(param_range, val_mean, 'o-', color='red', label='Validation Score')\n",
        "plt.fill_between(param_range, val_mean - val_std, val_mean + val_std, \n",
        "                 alpha=0.1, color='red')\n",
        "\n",
        "plt.xlabel('Max Depth')\n",
        "plt.ylabel('Accuracy Score')\n",
        "plt.title('Validation Curve: Decision Tree')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 4. Learning Curves - Understanding sample size impact\n",
        "print(\"\\n4. Learning Curves\")\n",
        "print(\"Analyzing how model performance changes with training set size...\")\n",
        "\n",
        "# Generate learning curve data\n",
        "train_sizes = np.linspace(0.1, 1.0, 10)\n",
        "train_sizes_abs, train_scores, val_scores = learning_curve(\n",
        "    RandomForestClassifier(random_state=42, n_estimators=100),\n",
        "    X_clf, y_clf, train_sizes=train_sizes, cv=5, scoring='accuracy', n_jobs=-1\n",
        ")\n",
        "\n",
        "# Calculate mean and std\n",
        "train_mean = np.mean(train_scores, axis=1)\n",
        "train_std = np.std(train_scores, axis=1)\n",
        "val_mean = np.mean(val_scores, axis=1)\n",
        "val_std = np.std(val_scores, axis=1)\n",
        "\n",
        "# Plot learning curve\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(train_sizes_abs, train_mean, 'o-', color='blue', label='Training Score')\n",
        "plt.fill_between(train_sizes_abs, train_mean - train_std, train_mean + train_std, \n",
        "                 alpha=0.1, color='blue')\n",
        "plt.plot(train_sizes_abs, val_mean, 'o-', color='red', label='Validation Score')\n",
        "plt.fill_between(train_sizes_abs, val_mean - val_std, val_mean + val_std, \n",
        "                 alpha=0.1, color='red')\n",
        "\n",
        "plt.xlabel('Training Set Size')\n",
        "plt.ylabel('Accuracy Score')\n",
        "plt.title('Learning Curve: Random Forest')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 5. Model Comparison with Statistical Significance\n",
        "print(\"\\n5. Model Comparison with Statistical Significance\")\n",
        "\n",
        "# Compare multiple models using cross-validation\n",
        "models_to_compare = {\n",
        "    'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000),\n",
        "    'Decision Tree': DecisionTreeClassifier(random_state=42),\n",
        "    'Random Forest': RandomForestClassifier(random_state=42, n_estimators=100),\n",
        "    'SVM': SVC(random_state=42)\n",
        "}\n",
        "\n",
        "# Perform cross-validation for each model\n",
        "cv_results = {}\n",
        "for name, model in models_to_compare.items():\n",
        "    scores = cross_val_score(model, X_clf, y_clf, cv=10, scoring='accuracy')\n",
        "    cv_results[name] = scores\n",
        "    print(f\"{name}: {scores.mean():.3f} (+/- {scores.std() * 2:.3f})\")\n",
        "\n",
        "# Visualize cross-validation results\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.boxplot([cv_results[name] for name in models_to_compare.keys()], \n",
        "            labels=list(models_to_compare.keys()))\n",
        "plt.ylabel('Accuracy Score')\n",
        "plt.title('Model Comparison: Cross-Validation Results')\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 6. Comprehensive Model Evaluation\n",
        "print(\"\\n6. Comprehensive Model Evaluation\")\n",
        "print(\"Using the best performing model for detailed analysis...\")\n",
        "\n",
        "# Select the best model based on cross-validation\n",
        "best_model_name = max(cv_results.keys(), key=lambda x: cv_results[x].mean())\n",
        "best_model = models_to_compare[best_model_name]\n",
        "\n",
        "print(f\"Best model: {best_model_name}\")\n",
        "print(f\"CV Score: {cv_results[best_model_name].mean():.3f} (+/- {cv_results[best_model_name].std() * 2:.3f})\")\n",
        "\n",
        "# Train on full dataset and evaluate\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_clf, y_clf, test_size=0.2, random_state=42)\n",
        "best_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = best_model.predict(X_test)\n",
        "\n",
        "# Calculate various metrics\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "print(f\"\\nDetailed Performance Metrics:\")\n",
        "print(f\"Accuracy: {accuracy:.3f}\")\n",
        "print(f\"Precision: {precision:.3f}\")\n",
        "print(f\"Recall: {recall:.3f}\")\n",
        "print(f\"F1-Score: {f1:.3f}\")\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "plt.title(f'Confusion Matrix: {best_model_name}')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n=== Model Evaluation Summary ===\")\n",
        "print(\"Key takeaways:\")\n",
        "print(\"1. Cross-validation provides more robust performance estimates\")\n",
        "print(\"2. Validation curves help identify optimal model complexity\")\n",
        "print(\"3. Learning curves show if more data would improve performance\")\n",
        "print(\"4. Multiple metrics give a complete picture of model performance\")\n",
        "print(\"5. Statistical significance testing helps compare models objectively\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
        "<h3>Exercise 12.1: Complete Machine Learning Pipeline</h3>\n",
        "\n",
        "<p><strong>Task:</strong> Build a complete machine learning pipeline using the Breast Cancer dataset.\n",
        "\n",
        "<p><strong>Requirements:</strong>\n",
        "<ul>\n",
        "<li>Load the Breast Cancer dataset from scikit-learn</li>\n",
        "<li>Perform exploratory data analysis (EDA)</li>\n",
        "<li>Split the data into training and testing sets</li>\n",
        "<li>Apply feature scaling</li>\n",
        "<li>Train multiple classification models</li>\n",
        "<li>Evaluate model performance using cross-validation</li>\n",
        "<li>Select the best model and make predictions</li>\n",
        "<li>Visualize results and feature importance</li>\n",
        "</ul>\n",
        "\n",
        "<p><strong>Models to implement:</strong>\n",
        "<ul>\n",
        "<li>Logistic Regression</li>\n",
        "<li>Decision Tree</li>\n",
        "<li>Random Forest</li>\n",
        "<li>SVM</li>\n",
        "<li>K-Nearest Neighbors</li>\n",
        "</ul>\n",
        "\n",
        "<p><strong>Evaluation metrics to calculate:</strong>\n",
        "<ul>\n",
        "<li>Accuracy, Precision, Recall, F1-Score</li>\n",
        "<li>Confusion Matrix</li>\n",
        "<li>Cross-validation scores</li>\n",
        "<li>ROC Curve and AUC (if applicable)</li>\n",
        "</ul>\n",
        "\n",
        "<p><strong>Bonus:</strong> Try applying PCA for dimensionality reduction and compare performance.\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Exercise 12.1: Complete Machine Learning Pipeline Solution\n",
        "# Load the Breast Cancer dataset\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import (accuracy_score, precision_score, recall_score, \n",
        "                           f1_score, confusion_matrix, classification_report,\n",
        "                           roc_auc_score, roc_curve)\n",
        "from sklearn.decomposition import PCA\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Load the dataset\n",
        "cancer = load_breast_cancer()\n",
        "X = cancer.data\n",
        "y = cancer.target\n",
        "feature_names = cancer.feature_names\n",
        "target_names = cancer.target_names\n",
        "\n",
        "print(\"=== Breast Cancer Dataset ===\")\n",
        "print(f\"Dataset shape: {X.shape}\")\n",
        "print(f\"Number of features: {X.shape[1]}\")\n",
        "print(f\"Number of samples: {X.shape[0]}\")\n",
        "print(f\"Target classes: {target_names}\")\n",
        "print(f\"Class distribution: {np.bincount(y)}\")\n",
        "\n",
        "# Create DataFrame for EDA\n",
        "df_cancer = pd.DataFrame(X, columns=feature_names)\n",
        "df_cancer['target'] = y\n",
        "df_cancer['diagnosis'] = [target_names[i] for i in y]\n",
        "\n",
        "print(\"\\n=== Dataset Overview ===\")\n",
        "print(df_cancer.head())\n",
        "\n",
        "print(\"\\n=== Basic Statistics ===\")\n",
        "print(df_cancer.describe())\n",
        "\n",
        "# Exploratory Data Analysis\n",
        "print(\"\\n=== Exploratory Data Analysis ===\")\n",
        "\n",
        "# Class distribution\n",
        "plt.figure(figsize=(15, 5))\n",
        "\n",
        "plt.subplot(1, 3, 1)\n",
        "class_counts = df_cancer['diagnosis'].value_counts()\n",
        "plt.pie(class_counts.values, labels=class_counts.index, autopct='%1.1f%%')\n",
        "plt.title('Class Distribution')\n",
        "\n",
        "# Feature correlation heatmap (top 10 features)\n",
        "plt.subplot(1, 3, 2)\n",
        "correlation_matrix = df_cancer.iloc[:, :10].corr()\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, fmt='.2f')\n",
        "plt.title('Feature Correlation (Top 10)')\n",
        "\n",
        "# Box plot of some key features\n",
        "plt.subplot(1, 3, 3)\n",
        "key_features = ['mean radius', 'mean texture', 'mean perimeter', 'mean area']\n",
        "df_cancer[key_features].boxplot()\n",
        "plt.title('Key Features Distribution')\n",
        "plt.xticks(rotation=45)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Feature scaling\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "print(f\"\\n=== Data Split ===\")\n",
        "print(f\"Training set size: {X_train.shape[0]} samples\")\n",
        "print(f\"Test set size: {X_test.shape[0]} samples\")\n",
        "\n",
        "# Train multiple models\n",
        "models = {\n",
        "    'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000),\n",
        "    'Decision Tree': DecisionTreeClassifier(random_state=42),\n",
        "    'Random Forest': RandomForestClassifier(random_state=42, n_estimators=100),\n",
        "    'SVM': SVC(random_state=42, probability=True),\n",
        "    'K-Nearest Neighbors': KNeighborsClassifier(n_neighbors=5)\n",
        "}\n",
        "\n",
        "results = {}\n",
        "\n",
        "print(\"\\n=== Training Models ===\")\n",
        "for name, model in models.items():\n",
        "    # Train the model\n",
        "    model.fit(X_train_scaled, y_train)\n",
        "    \n",
        "    # Make predictions\n",
        "    y_train_pred = model.predict(X_train_scaled)\n",
        "    y_test_pred = model.predict(X_test_scaled)\n",
        "    \n",
        "    # Calculate metrics\n",
        "    train_accuracy = accuracy_score(y_train, y_train_pred)\n",
        "    test_accuracy = accuracy_score(y_test, y_test_pred)\n",
        "    \n",
        "    # Cross-validation\n",
        "    cv_scores = cross_val_score(model, X_train_scaled, y_train, cv=5)\n",
        "    \n",
        "    # ROC AUC (for binary classification)\n",
        "    if hasattr(model, 'predict_proba'):\n",
        "        y_test_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
        "        roc_auc = roc_auc_score(y_test, y_test_proba)\n",
        "    else:\n",
        "        roc_auc = None\n",
        "    \n",
        "    results[name] = {\n",
        "        'model': model,\n",
        "        'train_accuracy': train_accuracy,\n",
        "        'test_accuracy': test_accuracy,\n",
        "        'cv_mean': cv_scores.mean(),\n",
        "        'cv_std': cv_scores.std(),\n",
        "        'predictions': y_test_pred,\n",
        "        'roc_auc': roc_auc\n",
        "    }\n",
        "    \n",
        "    print(f\"{name}:\")\n",
        "    print(f\"  Training Accuracy: {train_accuracy:.3f}\")\n",
        "    print(f\"  Test Accuracy: {test_accuracy:.3f}\")\n",
        "    print(f\"  CV Accuracy: {cv_scores.mean():.3f} (+/- {cv_scores.std() * 2:.3f})\")\n",
        "    if roc_auc:\n",
        "        print(f\"  ROC AUC: {roc_auc:.3f}\")\n",
        "    print()\n",
        "\n",
        "# Model comparison\n",
        "print(\"=== Model Comparison ===\")\n",
        "comparison_df = pd.DataFrame({\n",
        "    'Model': list(results.keys()),\n",
        "    'Train Accuracy': [results[name]['train_accuracy'] for name in results.keys()],\n",
        "    'Test Accuracy': [results[name]['test_accuracy'] for name in results.keys()],\n",
        "    'CV Mean': [results[name]['cv_mean'] for name in results.keys()],\n",
        "    'CV Std': [results[name]['cv_std'] for name in results.keys()],\n",
        "    'ROC AUC': [results[name]['roc_auc'] for name in results.keys()]\n",
        "})\n",
        "\n",
        "print(comparison_df.round(3))\n",
        "\n",
        "# Visualize model performance\n",
        "plt.figure(figsize=(15, 5))\n",
        "\n",
        "plt.subplot(1, 3, 1)\n",
        "x_pos = np.arange(len(results))\n",
        "plt.bar(x_pos, [results[name]['test_accuracy'] for name in results.keys()])\n",
        "plt.xlabel('Model')\n",
        "plt.ylabel('Test Accuracy')\n",
        "plt.title('Model Performance Comparison')\n",
        "plt.xticks(x_pos, list(results.keys()), rotation=45)\n",
        "\n",
        "plt.subplot(1, 3, 2)\n",
        "cv_means = [results[name]['cv_mean'] for name in results.keys()]\n",
        "cv_stds = [results[name]['cv_std'] for name in results.keys()]\n",
        "plt.bar(x_pos, cv_means, yerr=cv_stds, capsize=5)\n",
        "plt.xlabel('Model')\n",
        "plt.ylabel('CV Accuracy')\n",
        "plt.title('Cross-Validation Results')\n",
        "plt.xticks(x_pos, list(results.keys()), rotation=45)\n",
        "\n",
        "plt.subplot(1, 3, 3)\n",
        "roc_aucs = [results[name]['roc_auc'] for name in results.keys() if results[name]['roc_auc']]\n",
        "roc_names = [name for name in results.keys() if results[name]['roc_auc']]\n",
        "plt.bar(range(len(roc_aucs)), roc_aucs)\n",
        "plt.xlabel('Model')\n",
        "plt.ylabel('ROC AUC')\n",
        "plt.title('ROC AUC Comparison')\n",
        "plt.xticks(range(len(roc_names)), roc_names, rotation=45)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Select best model\n",
        "best_model_name = max(results.keys(), key=lambda x: results[x]['test_accuracy'])\n",
        "best_model = results[best_model_name]['model']\n",
        "best_predictions = results[best_model_name]['predictions']\n",
        "\n",
        "print(f\"\\n=== Best Model: {best_model_name} ===\")\n",
        "print(f\"Test Accuracy: {results[best_model_name]['test_accuracy']:.3f}\")\n",
        "print(f\"CV Score: {results[best_model_name]['cv_mean']:.3f} (+/- {results[best_model_name]['cv_std'] * 2:.3f})\")\n",
        "\n",
        "# Detailed evaluation\n",
        "print(\"\\n=== Detailed Evaluation ===\")\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, best_predictions, target_names=target_names))\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_test, best_predictions)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
        "            xticklabels=target_names, yticklabels=target_names)\n",
        "plt.title(f'Confusion Matrix: {best_model_name}')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.show()\n",
        "\n",
        "# Feature importance (for tree-based models)\n",
        "if hasattr(best_model, 'feature_importances_'):\n",
        "    print(f\"\\n=== Feature Importance: {best_model_name} ===\")\n",
        "    feature_importance = pd.DataFrame({\n",
        "        'Feature': feature_names,\n",
        "        'Importance': best_model.feature_importances_\n",
        "    }).sort_values('Importance', ascending=False)\n",
        "    \n",
        "    print(feature_importance.head(10))\n",
        "    \n",
        "    # Plot top 15 features\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    top_features = feature_importance.head(15)\n",
        "    plt.barh(top_features['Feature'], top_features['Importance'])\n",
        "    plt.xlabel('Importance')\n",
        "    plt.title(f'Top 15 Feature Importance: {best_model_name}')\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# ROC Curve\n",
        "if hasattr(best_model, 'predict_proba'):\n",
        "    y_test_proba = best_model.predict_proba(X_test_scaled)[:, 1]\n",
        "    fpr, tpr, _ = roc_curve(y_test, y_test_proba)\n",
        "    roc_auc = roc_auc_score(y_test, y_test_proba)\n",
        "    \n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.plot(fpr, tpr, color='darkorange', lw=2, \n",
        "             label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
        "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title(f'ROC Curve: {best_model_name}')\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.show()\n",
        "\n",
        "print(\"\\n=== Exercise Complete ===\")\n",
        "print(\"Successfully implemented a complete machine learning pipeline!\")\n",
        "print(\"Key achievements:\")\n",
        "print(\"1. ✅ Loaded and explored the Breast Cancer dataset\")\n",
        "print(\"2. ✅ Performed comprehensive EDA\")\n",
        "print(\"3. ✅ Trained multiple classification models\")\n",
        "print(\"4. ✅ Evaluated models using cross-validation\")\n",
        "print(\"5. ✅ Selected the best performing model\")\n",
        "print(\"6. ✅ Generated detailed performance metrics and visualizations\")\n",
        "print(\"7. ✅ Analyzed feature importance and ROC curves\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
        "<h2>6. Summary: Scikit-Learn Mastery</h2>\n",
        "\n",
        "<p>Congratulations! You've completed a comprehensive introduction to scikit-learn, the most popular machine learning library in Python. Let's summarize what you've learned and the key takeaways.\n",
        "\n",
        "<p><strong>Key Concepts Mastered:</strong>\n",
        "<ul>\n",
        "<li><strong>Scikit-Learn API:</strong> Consistent fit/predict/transform pattern across all algorithms</li>\n",
        "<li><strong>Linear Regression:</strong> Predicting continuous values with linear relationships</li>\n",
        "<li><strong>Principal Component Analysis (PCA):</strong> Dimensionality reduction and data visualization</li>\n",
        "<li><strong>Classification:</strong> Categorizing data using various algorithms</li>\n",
        "<li><strong>Model Evaluation:</strong> Comprehensive assessment using multiple metrics and validation techniques</li>\n",
        "<li><strong>Complete Pipeline:</strong> End-to-end machine learning workflow</li>\n",
        "</ul>\n",
        "\n",
        "<p><strong>Algorithms Covered:</strong>\n",
        "<ul>\n",
        "<li><strong>Regression:</strong> Linear Regression, Ridge, Lasso</li>\n",
        "<li><strong>Classification:</strong> Logistic Regression, Decision Trees, Random Forest, SVM, KNN</li>\n",
        "<li><strong>Dimensionality Reduction:</strong> PCA</li>\n",
        "<li><strong>Preprocessing:</strong> StandardScaler, train_test_split</li>\n",
        "</ul>\n",
        "\n",
        "<p><strong>Evaluation Techniques:</strong>\n",
        "<ul>\n",
        "<li><strong>Cross-Validation:</strong> K-fold, stratified, leave-one-out</li>\n",
        "<li><strong>Metrics:</strong> Accuracy, Precision, Recall, F1-Score, ROC-AUC</li>\n",
        "<li><strong>Visualization:</strong> Confusion matrices, ROC curves, learning curves</li>\n",
        "<li><strong>Model Selection:</strong> Validation curves, feature importance</li>\n",
        "</ul>\n",
        "\n",
        "<p><strong>Best Practices Learned:</strong>\n",
        "<ul>\n",
        "<li><strong>Data Preprocessing:</strong> Always scale features for distance-based algorithms</li>\n",
        "<li><strong>Train-Test Split:</strong> Use proper validation to avoid overfitting</li>\n",
        "<li><strong>Cross-Validation:</strong> More robust than single train-test split</li>\n",
        "<li><strong>Multiple Metrics:</strong> Don't rely on accuracy alone</li>\n",
        "<li><strong>Feature Engineering:</strong> PCA and other techniques can improve performance</li>\n",
        "<li><strong>Model Comparison:</strong> Always compare multiple algorithms</li>\n",
        "</ul>\n",
        "\n",
        "<p><strong>Real-World Applications:</strong>\n",
        "<ul>\n",
        "<li><strong>Boston Housing:</strong> Real estate price prediction</li>\n",
        "<li><strong>Iris Dataset:</strong> Species classification and dimensionality reduction</li>\n",
        "<li><strong>Wine Dataset:</strong> Wine quality classification</li>\n",
        "<li><strong>Breast Cancer:</strong> Medical diagnosis and feature importance analysis</li>\n",
        "</ul>\n",
        "\n",
        "<p><strong>Next Steps for Advanced Learning:</strong>\n",
        "<ul>\n",
        "<li><strong>Hyperparameter Tuning:</strong> GridSearchCV, RandomizedSearchCV</li>\n",
        "<li><strong>Ensemble Methods:</strong> Voting, Bagging, Boosting</li>\n",
        "<li><strong>Advanced Algorithms:</strong> Neural Networks, Clustering, Anomaly Detection</li>\n",
        "<li><strong>Feature Engineering:</strong> Polynomial features, interaction terms</li>\n",
        "<li><strong>Model Deployment:</strong> Saving models, API development</li>\n",
        "</ul>\n",
        "\n",
        "<p><strong>Scikit-Learn Strengths:</strong>\n",
        "<ul>\n",
        "<li><strong>Consistency:</strong> Same API for all algorithms</li>\n",
        "<li><strong>Completeness:</strong> Covers most machine learning needs</li>\n",
        "<li><strong>Documentation:</strong> Excellent docs and examples</li>\n",
        "<li><strong>Performance:</strong> Optimized C implementations</li>\n",
        "<li><strong>Community:</strong> Large, active user base</li>\n",
        "</ul>\n",
        "\n",
        "<p><strong>When to Use Scikit-Learn:</strong>\n",
        "<ul>\n",
        "<li><strong>Traditional ML:</strong> Perfect for classical algorithms</li>\n",
        "<li><strong>Prototyping:</strong> Quick experimentation and proof-of-concept</li>\n",
        "<li><strong>Educational:</strong> Great for learning ML concepts</li>\n",
        "<li><strong>Production:</strong> Reliable for many real-world applications</li>\n",
        "<li><strong>Integration:</strong> Works well with other Python libraries</li>\n",
        "</ul>\n",
        "\n",
        "<p><strong>Remember:</strong> Scikit-learn is a powerful tool, but it's just one part of the machine learning ecosystem. Combine it with other libraries like pandas for data manipulation, matplotlib/seaborn for visualization, and specialized libraries for deep learning when needed.\n",
        "\n",
        "<p><strong>Practice Recommendations:</strong>\n",
        "<ul>\n",
        "<li>Try the exercises with different datasets</li>\n",
        "<li>Experiment with hyperparameter tuning</li>\n",
        "<li>Implement your own feature engineering techniques</li>\n",
        "<li>Explore the scikit-learn documentation and examples</li>\n",
        "<li>Join the scikit-learn community and contribute</li>\n",
        "</ul>\n",
        "\n",
        "<p><strong>Final Thoughts:</strong> You now have a solid foundation in scikit-learn and machine learning with Python. The key to mastery is practice - keep experimenting with different datasets, algorithms, and techniques. Machine learning is both an art and a science, and scikit-learn provides the perfect toolkit to explore this fascinating field.\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
